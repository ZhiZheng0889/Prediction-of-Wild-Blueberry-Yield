---
title: "R Notebook"
output: html_notebook
---

```{r}
library(h2o)
library(tidyr)
library(dplyr)
library(readr)

# Initialize H2O
h2o.init()

# Custom function for calculating Mean Absolute Error using competition training data
fold_mae <- function(y, preds, data_type) {
  y_comp <- y[data_type == 0]
  preds_comp <- preds[data_type == 0]
  return(mean(abs(y_comp - preds_comp)))
}

# Load the datasets
train_data <- read_csv("train.csv")
test_data <- read_csv("test.csv")

# Preprocess the data
train_data$data_type <- 0
test_data$data_type <- 0

INCLUDE_ORIGINAL <- TRUE

if (INCLUDE_ORIGINAL) {
  original_data <- read.csv('WildBlueberryPollinationSimulationData.csv')
  original_data$data_type <- 1
  train_data <- rbind(train_data, original_data[, -which(colnames(original_data) %in% 'Row#')])
}

# Feature engineering
fe <- function(df) {
  df$RainingDays <- ifelse(df$RainingDays == 26, 24,
                           ifelse(df$RainingDays == 33, 34, df$RainingDays))
  return(df)
}

train_data <- fe(train_data)
test_data <- fe(test_data)

# Convert the datasets to H2OFrame
train_h2o <- as.h2o(train_data)
test_h2o <- as.h2o(test_data)

# Set the features, target, and other settings for AutoML
features <- colnames(train_h2o)[-which(colnames(train_h2o) %in% c('yield', 'data_type'))]
target <- 'yield'

# AutoML settings
time_budget <- 3600  # Set the time budget (in seconds) for AutoML
n_folds <- 5  # Set the number of folds for cross-validation
random_seed <- 42  # Set the random seed for reproducibility

# Run H2O's AutoML
aml <- h2o.automl(
  x = features,
  y = target,
  training_frame = train_h2o,
  nfolds = n_folds,
  max_runtime_secs = time_budget,
  seed = random_seed,
  include_algos = c("XGBoost", "GLM", "DeepLearning", "DRF")
)

# Extract the best model
best_model <- aml@leader

# Make predictions on the test set
test_preds <- h2o.predict(best_model, test_h2o)

# Make predictions on the training set and calculate the fold MAE
train_preds <- h2o.predict(best_model, train_h2o)
mae_result <- fold_mae(train_data$yield, as.vector(train_preds$predict), train_data$data_type)

print(paste0("Fold MAE: ", mae_result))

# Shutdown H2O
h2o.shutdown(prompt = FALSE)

```

```{r}

# Initialize H2O
h2o.init()

# Custom function for calculating Mean Absolute Error using competition training data
fold_mae <- function(y, preds, data_type) {
  y_comp <- y[data_type == 0]
  preds_comp <- preds[data_type == 0]
  return(mean(abs(y_comp - preds_comp)))
}

# Convert data frames to H2O objects
train_h2o <- as.h2o(train_data)
test_h2o <- as.h2o(test_data)

# Set the features, target, and other settings for AutoML
features <- colnames(train_h2o)[-which(colnames(train_h2o) %in% c('yield', 'data_type'))]
target <- 'yield'

# AutoML settings
time_budget <- 3600  # Set the time budget (in seconds) for AutoML
n_folds <- 5  # Set the number of folds for cross-validation
random_seed <- 42  # Set the random seed for reproducibility

# Run H2O's AutoML
aml <- h2o.automl(
  x = features,
  y = target,
  training_frame = train_h2o,
  nfolds = n_folds,
  max_runtime_secs = time_budget,
  seed = random_seed,
  include_algos = c("XGBoost", "GLM", "DeepLearning", "DRF")
)

# Extract the best model
best_model <- aml@leader

# Make predictions on the test set
test_preds <- h2o.predict(best_model, test_h2o)

# Make predictions on the training set and calculate the fold MAE
train_preds <- h2o.predict(best_model, train_h2o)
mae_result <- fold_mae(train_data$yield, as.vector(train_preds$predict), train_data$data_type)

print(paste0("Fold MAE: ", mae_result))

```

```{r}
# Initialize H2O
h2o.init()

# Define the features and target variables
features <- colnames(train_data)[colnames(train_data) != "id" & colnames(train_data) != "yield"]
target <- "yield"

# Convert the datasets to H2OFrame
train_h2o <- as.h2o(train_data)
test_h2o <- as.h2o(test_data)

# Define the constants for the number of outer folds, number of repeats, and the random seed
n_outer_folds <- 5
n_repeats <- 3
random_seed <- 42

# Train the H2O AutoML model
aml <- h2o.automl(
  x = features,
  y = target,
  training_frame = train_h2o,
  nfolds = n_outer_folds,
  max_runtime_secs = 600, # adjust the time budget as needed
  seed = random_seed
)

# Get the best model
best_model <- aml@leader

# Make predictions using the best model
test_preds <- h2o.predict(best_model, test_h2o)

# Save the predictions to a CSV file
submission <- data.frame(id = test_data$id, yield = as.vector(test_preds$predict))
write.csv(submission, "submission2.csv", row.names = FALSE)

# Shutdown H2O
h2o.shutdown(prompt = FALSE)

```

```{r}
# Initialize H2O
h2o.init()

# Define the features and target variables
features <- colnames(train_data)[colnames(train_data) != "id" & colnames(train_data) != "yield"]
target <- "yield"

# Convert the datasets to H2OFrame
train_h2o <- as.h2o(train_data)
test_h2o <- as.h2o(test_data)

# Set the random seed
random_seed <- 42

# Shuffle the train_data
set.seed(random_seed)
train_data <- train_data[sample(nrow(train_data)),]

# H2O AutoML settings
first_time_budget <- 600
min_time_budget <- 60
n_folds <- 5

# Train the H2O AutoML model with custom LGBM settings
automl_settings <- list(
  nfolds = n_folds,
  max_runtime_secs = first_time_budget,
  seed = random_seed,
  include_algos = c("XGBoost", "GLM", "DeepLearning", "DRF"),
  custom_hyperparams = list(
    my_lgbm = list(
      n_estimators = 265,
      num_leaves = 93,
      min_child_samples = 20,
      learning_rate = 0.05533790147941807,
      log_max_bin = 10,
      colsample_bytree = 0.8809128870084636,
      reg_alpha = 0.0009765625,
      reg_lambda = 0.015589408048174165
    )
  )
)

aml <- h2o.automl(
  x = features,
  y = target,
  training_frame = train_h2o,
  nfolds = n_folds,
  max_runtime_secs = first_time_budget,
  seed = random_seed,
  include_algos = c("XGBoost", "GLM", "DeepLearning", "DRF")
)

# Get the best model
best_model <- aml@leader

# Make predictions using the best model
test_preds <- h2o.predict(best_model, test_h2o)

# Save the predictions to a CSV file
submission <- data.frame(id = test_data$id, yield = as.vector(test_preds$predict))
write.csv(submission, "submission3.csv", row.names = FALSE)

# Shutdown H2O
h2o.shutdown(prompt = FALSE)

```


```{r}
# Load required libraries
library(h2o)
library(tidyr)
library(dplyr)
library(readr)

# Initialize H2O
h2o.init()

# Load the datasets
train_data <- read_csv("train.csv")
test_data <- read_csv("test.csv")

# Preprocess the data
train_data$data_type <- 0
test_data$data_type <- 0

# Feature engineering
fe <- function(df) {
  df$RainingDays <- ifelse(df$RainingDays == 26, 24,
                           ifelse(df$RainingDays == 33, 34, df$RainingDays))
  return(df)
}

train_data <- fe(train_data)
test_data <- fe(test_data)

# Convert the datasets to H2OFrame
train_h2o <- as.h2o(train_data)
test_h2o <- as.h2o(test_data)

# Set the features, target, and other settings for AutoML
features <- colnames(train_h2o)[-which(colnames(train_h2o) %in% c('yield', 'data_type'))]
target <- 'yield'

# AutoML settings
time_budget <- 3600  # Set the time budget (in seconds) for AutoML
n_folds <- 5  # Set the number of folds for cross-validation
random_seed <- 42  # Set the random seed for reproducibility

# Run H2O's AutoML with GBM algorithm
aml <- h2o.automl(
  x = features,
  y = target,
  training_frame = train_h2o,
  nfolds = n_folds,
  max_runtime_secs = time_budget,
  seed = random_seed,
  include_algos = c("GBM")
)

# Extract the best model
best_model <- aml@leader

# Make predictions on the test set
test_preds <- h2o.predict(best_model, test_h2o)

# Create the submission file
submission <- data.frame(id = test_data$id, yield = as.vector(test_preds$predict))
write.csv(submission, "submission4.csv", row.names = FALSE)

# Shutdown H2O
h2o.shutdown(prompt = FALSE)


```

